{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We're scraping\n",
    "\n",
    "Probably going to just scrape it all. \n",
    "\n",
    "See [baseball-scraper](https://pypi.org/project/baseball-scraper/) for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseball_scraper import statcast\n",
    "from baseball_scraper import playerid_lookup\n",
    "\n",
    "import pandas as pd \n",
    "import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##What happens if I ask for a date on which no games are played... \n",
    "##Like I write a function and uh-oh, all-star break included...\n",
    "\n",
    "##Looking for a date pre statcast gives a table with lots of NaN values. \n",
    "#pre_stat_scrape = statcast(start_dt='2010-08-08', verbose=True)\n",
    "\n",
    "##Looking for a date on which no games were played gives a dataframe of shape 0x90\n",
    "#january_scrape = statcast(start_dt='2018-01-01', verbose=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2020-07-23'"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "start = datetime.date(2020,7,23).strftime(\"%Y-%m-%d\")\n",
    "end = datetime.date(2020,8,18).strftime(\"%Y-%m-%d\")##This is the world's third hardest way to write '2020-08-18', but you're maybe using it later.\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Scrapes time slices based on a date range. Returns a list of successfully scraped time slices.\n",
    "\n",
    "def big_scrape(start,end):\n",
    "    '''\n",
    "    Returns a DataFrame of all the successfull scraped time slices in range start, end. \n",
    "    \n",
    "    If an exception is raised, prints a brief report, stops scraping, and returns\n",
    "    all the successfully scraped slices.\n",
    "    '''\n",
    "    scrapes = [] ##\n",
    "    while True:\n",
    "        try:\n",
    "            temp = statcast(start.strftime(\"%Y-%m-%d\"), (start+datetime.timedelta(days=4)).strftime(\"%Y-%m-%d\"))\n",
    "        except ParserError:\n",
    "            print(\"ParserError failure at {}\".format(start.strftime(\"%Y-%m-%d\")))\n",
    "            break\n",
    "        except:\n",
    "            print(\"Unspecified failure at {}\".format(start.strftime(\"%Y-%m-%d\")))\n",
    "            break\n",
    "        scrapes.append(temp)\n",
    "        start = start+datetime.timedelta(days=5)\n",
    "        if start > end:\n",
    "            break\n",
    "    return pd.concat(scrapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Skipping the season scrape. To scrape, set no_really to True\n"
    }
   ],
   "source": [
    "## Creates all the .csv files.\n",
    "\n",
    "no_really = False ##Just prevents accidentally running this cell if you have already run it and don't need to do it again.\n",
    "                  ##These files are very big (300+MB) and take a long time to scrape.\n",
    "\n",
    "if no_really:\n",
    "    for dt in [2019,2018,2017,2016]:\n",
    "        start = datetime.date(dt,3,20)\n",
    "        end = datetime.date(dt,10,1)\n",
    "        scrape = big_scrape(start,end)\n",
    "        scrape.to_csv('data/statcast_dumps/statcast'+str(dt)+'.csv')\n",
    "        print(\"Finished with statcast year {}.\".format(dt))\n",
    "        del scrape\n",
    "else:\n",
    "    print(\"Skipping the season scrape. To scrape, set no_really to True\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## updating the current year efficiently\n",
    "\n",
    "def update_statcast(target_csv_name):\n",
    "    '''\n",
    "    Scapes any statcast data after the last game_date \n",
    "    in the year of the target file and adds it, returning a DataFrame that concatenates the\n",
    "    new data with the old.\n",
    "    \n",
    "    '''\n",
    "    out = pd.read_csv(target_csv_name)\n",
    "    start = pd.Timestamp(out['game_date'].sort_values().iloc[-1])\n",
    "    end = datetime.datetime.now()\n",
    "    new = big_scrape(start, end)\n",
    "    out = pd.concat([out,new])\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_2020 = 'data/statcast_dumps/statcast2020.csv'\n",
    "sc_2020 = update_statcast(csv_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_2020.to_csv(csv_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}