{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We're scraping\n",
    "\n",
    "Probably going to just scrape it all. \n",
    "\n",
    "See [baseball-scraper](https://pypi.org/project/baseball-scraper/) for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseball_scraper import statcast\n",
    "from baseball_scraper import playerid_lookup\n",
    "\n",
    "import pandas as pd \n",
    "import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2018-01-01'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "##What happens if I ask for a date on which no games are played... \n",
    "##Like I write a function and uh-oh, all-star break included...\n",
    "\n",
    "##Looking for a date pre statcast gives a table with lots of NaN values. \n",
    "#pre_stat_scrape = statcast(start_dt='2010-08-08', verbose=True)\n",
    "\n",
    "##Looking for a date on which no games were played gives a dataframe of shape 0x90\n",
    "#january_scrape = statcast(start_dt='2018-01-01', verbose=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "This is a large query, it may take a moment to complete\nCompleted sub-query from 2020-07-23 to 2020-07-28\nCompleted sub-query from 2020-07-29 to 2020-08-03\nCompleted sub-query from 2020-08-04 to 2020-08-09\nCompleted sub-query from 2020-08-10 to 2020-08-15\nCompleted sub-query from 2020-08-16 to 2020-08-18\n"
    }
   ],
   "source": [
    "start = datetime.date(2020,7,23).strftime(\"%Y-%m-%d\")\n",
    "end = datetime.date(2020,8,18).strftime(\"%Y-%m-%d\")##This is the world's third hardest way to write '2020-08-18', but you're maybe using it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2020-08-19 10:32:58.162340\n2020-08-19 10:32:58.162670\n"
    }
   ],
   "source": [
    "## Scrapes time slices based on a date range. Returns a list of successfully scraped time slices.\n",
    "\n",
    "def big_scrape(start,end):\n",
    "    '''\n",
    "    Returns a list of all the successfull scraped time slices in range start, end. \n",
    "    \n",
    "    If an exception     is raised, prints a brief report, stops scraping, and returns\n",
    "    all the successfully scraped slices.\n",
    "    '''\n",
    "    scrapes = [] ##\n",
    "    while True:\n",
    "        try:\n",
    "            temp = statcast(start.strftime(\"%Y-%m-%d\"), (start+datetime.timedelta(days=4)).strftime(\"%Y-%m-%d\"))\n",
    "        except ParserError:\n",
    "            print(\"ParserError failure at {}\".format(start.strftime(\"%Y-%m-%d\")))\n",
    "            break\n",
    "        except:\n",
    "            print(\"Unspecified failure at {}\".format(start.strftime(\"%Y-%m-%d\")))\n",
    "            break\n",
    "        scrapes.append(temp)\n",
    "        start = start+datetime.timedelta(days=5)\n",
    "        if start > end:\n",
    "            break\n",
    "    return scrapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Finished with statcast year 2019.\nFinished with statcast year 2018.\nFinished with statcast year 2017.\nFinished with statcast year 2016.\n"
    }
   ],
   "source": [
    "## Creates all the .csv files.\n",
    "\n",
    "for dt in [2019,2018,2017,2016]:\n",
    "    start = datetime.date(dt,3,20)\n",
    "    end = datetime.date(dt,10,1)\n",
    "    scrape = big_scrape(start,end)\n",
    "    pd.concat(scrape).to_csv('data/statcast_dumps/statcast'+str(dt)+'.csv')\n",
    "    print(\"Finished with statcast year {}.\".format(dt))\n",
    "    del scrape"
   ]
  }
 ]
}