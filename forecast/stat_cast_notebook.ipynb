{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whoo hoo statcast\n",
    "\n",
    "Could it get better? Physics data available for me to play with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "statcast = pd.read_csv('../data/hitters_statcast_since2016.csv').dropna()\n",
    "statcast['Barrel%'] = statcast['Barrel%'].apply(lambda x: float(x.strip('%')))\n",
    "statcast['HardHit%'] = statcast['HardHit%'].apply(lambda x: float(x.strip('%')))\n",
    "\n",
    "##Introduce a number of physical quantities, very approximate.\n",
    "statcast['cosLA'] = np.cos(statcast['LA']/180*np.pi)\n",
    "statcast['sinLA'] = np.sin(statcast['LA']/180*np.pi)\n",
    "statcast['EV_x'] = statcast['EV']*statcast['cosLA']\n",
    "statcast['EV_y'] = statcast['EV']*statcast['sinLA']\n",
    "acceleration = -32 * 60 * 60 / 5280\n",
    "func = (lambda x: -2 * x / acceleration)\n",
    "statcast['Hangtime'] = func(statcast['EV_y'])\n",
    "statcast['Distance'] = statcast['Hangtime']*statcast['EV_x']\n",
    "\n",
    "## We know that the optimal LA for homeruns is not 0 degrees.\n",
    "## Below, we found that an average LA of 20 was very good for HR\n",
    "## hitting. We score this by the cosine squared.\n",
    "\n",
    "statcast['LA_optimality'] = np.cos((statcast['LA'] - 20)/180*np.pi)**2\n",
    "\n",
    "##In particluar, that LA_optimality times av. exist velocity correlated well with \n",
    "##HR%. So, let's add that too\n",
    "\n",
    "\n",
    "\n",
    "standard = pd.read_csv('../data/hitters_since_1947.csv')\n",
    "standard = standard[standard['Season'] >= 2016]\n",
    "standard.drop(['G','AB','AVG','R','RBI'], axis = 1, inplace=True)\n",
    "\n",
    "statcast_cols = statcast.select_dtypes(exclude = 'object').drop(['playerid','Season'], axis = 1).columns \n",
    "standard_cols = standard.select_dtypes(exclude = 'object').drop(['playerid','Season'], axis = 1).columns\n",
    "\n",
    "df = pd.merge(statcast, standard.select_dtypes(exclude='object'), on = ['playerid','Season'], how = 'left').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['Season', 'Name', 'Team', 'PA_x', 'Events', 'EV', 'maxEV', 'LA',\n       'Barrels', 'Barrel%', 'HardHit', 'HardHit%', 'playerid', 'cosLA',\n       'sinLA', 'EV_x', 'EV_y', 'Hangtime', 'Distance', 'LA_optimality', 'PA',\n       'H', '1B', '2B', '3B', 'HR', 'BB', 'IBB', 'SO', 'HBP', 'SF', 'SH',\n       'GDP', 'SB', 'CS', 'PA%', 'H%', '1B%', '2B%', '3B%', 'HR%', 'BB%',\n       'IBB%', 'SO%', 'HBP%', 'SF%', 'SH%', 'GDP%', 'SB%', 'CS%'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "df.rename({'PA_y':'PA'}, axis=1, inplace = True)\n",
    "for s in standard_cols:\n",
    "    df[s+'%'] = df[s]/df['Events']\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiseason_lines(df, stats, num_seasons):\n",
    "    \"\"\"\n",
    "    Adds columns to rows in a DataFrame for previous seasons; useful for making past seasons features\n",
    "    in ML applicaitons.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        A DataFrame that includes multiple seasons of player data in separate rows.\n",
    "        The DataFrame must include a unique 'playerid' column (per Fangraphs) and \n",
    "        the seasons must be labeled 'Season' with int-type data.\n",
    "    stats: list-like\n",
    "        The stats to include from previous seasons.\n",
    "\n",
    "    num_seasons: int\n",
    "        The number of past seasons to include as past stats.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A DataFrame with the columns from df and additional columns from stats\n",
    "        labeled with suffixes '_1', '_2'...'_x' for the past season's stats.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "        >>> df\n",
    "        playerid | Season | Player | Batting Average\n",
    "        001        2001     Ichiro   .350\n",
    "        001        2002     Ichiro   .321\n",
    "        >>> multiseason_lines(df, ['Batting_Average'], 1)\n",
    "        playerid | Season | Player | Batting Average | Batting Average_1\n",
    "        001        2002     Ichiro   .350              .321\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    for n in range(num_seasons):\n",
    "        df1 = df.copy()\n",
    "        df1['Season'] = df1['Season'] + 1 + n ##we set df1 to match df, except that all season numbers are incremented.\n",
    "        out = pd.merge(out, df1[stats], how = 'left', on=['playerid','Season'], #then we can align a previous season with a current one.\n",
    "            suffixes=(\"\",\"_\"+str(1+n)))\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0       3\n1       1\n2       1\n3       2\n4       2\n       ..\n4034    1\n4035    1\n4036    1\n4037    1\n4038    1\nName: Events, Length: 3561, dtype: int64"
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "source": [
    "df['Events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['Season', 'Name', 'Team', 'PA_x', 'Events', 'EV', 'maxEV', 'LA',\n       'Barrels', 'Barrel%', 'HardHit', 'HardHit%', 'playerid', 'cosLA',\n       'sinLA', 'EV_x', 'EV_y', 'Hangtime', 'Distance', 'LA_optimality', 'PA',\n       'H', '1B', '2B', '3B', 'HR', 'BB', 'IBB', 'SO', 'HBP', 'SF', 'SH',\n       'GDP', 'SB', 'CS', 'PA%', 'H%', '1B%', '2B%', '3B%', 'HR%', 'BB%',\n       'IBB%', 'SO%', 'HBP%', 'SF%', 'SH%', 'GDP%', 'SB%', 'CS%', 'PA_x_1',\n       'Events_1', 'EV_1', 'maxEV_1', 'LA_1', 'Barrels_1', 'Barrel%_1',\n       'HardHit_1', 'HardHit%_1', 'cosLA_1', 'sinLA_1', 'EV_x_1', 'EV_y_1',\n       'Hangtime_1', 'Distance_1', 'LA_optimality_1', 'PA_1', 'H_1', '1B_1',\n       '2B_1', '3B_1', 'HR_1', 'BB_1', 'IBB_1', 'SO_1', 'HBP_1', 'SF_1',\n       'SH_1', 'GDP_1', 'SB_1', 'CS_1', 'PA%_1', 'H%_1', '1B%_1', '2B%_1',\n       '3B%_1', 'HR%_1', 'BB%_1', 'IBB%_1', 'SO%_1', 'HBP%_1', 'SF%_1',\n       'SH%_1', 'GDP%_1', 'SB%_1', 'CS%_1'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "stats = df.select_dtypes(exclude='object').columns\n",
    "df = multiseason_lines(df,stats,1).dropna()\n",
    "event_threshold = 100\n",
    "df = df[(df['Events'] > event_threshold) & (df['Events_1']> event_threshold)]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "144"
     },
     "metadata": {},
     "execution_count": 172
    }
   ],
   "source": [
    "correlations = df.corr()\n",
    "df['PA_x'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = df['HR%']\n",
    "data = df[[ x for x in df.select_dtypes(exclude='object').columns if x.endswith(\"_1\")]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PA_x_1: -0.69\nEvents_1: -0.97\nEV_1: 0.09\nmaxEV_1: 0.08\nLA_1: -0.27\nBarrels_1: 0.11\nBarrel%_1: 0.35\nHardHit_1: -0.44\nHardHit%_1: 0.16\ncosLA_1: -1.73\nsinLA_1: -0.27\nEV_x_1: -0.46\nEV_y_1: -0.20\nHangtime_1: -0.20\nDistance_1: -0.13\nLA_optimality_1: -0.32\nPA_1: -0.69\nH_1: -0.84\n1B_1: -1.22\n2B_1: -0.70\n3B_1: -1.24\nHR_1: 0.03\nBB_1: -0.41\nIBB_1: -0.62\nSO_1: -0.15\nHBP_1: -0.82\nSF_1: -0.84\nSH_1: -1.66\nGDP_1: -0.89\nSB_1: -1.34\nCS_1: -1.35\nPA%_1: -0.07\nH%_1: -0.45\n1B%_1: -1.60\n2B%_1: -0.49\n3B%_1: -1.31\nHR%_1: 0.26\nBB%_1: -0.30\nIBB%_1: -0.61\nSO%_1: -0.13\nHBP%_1: -0.87\nSF%_1: -0.85\nSH%_1: -1.58\nGDP%_1: -0.89\nSB%_1: -1.38\nCS%_1: -1.37\n"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "for e in data.columns:\n",
    "    x = scaler.fit_transform(target.to_frame())\n",
    "    y = scaler.fit_transform(data[e].to_frame())\n",
    "    print(\"{}: {:.2f}\".format(e, r2_score(x,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establishing a Baseline\n",
    "\n",
    "Any decent information we get should improve on using a simple linear regression of a previous season's HR total.\n",
    "So, we findout how that scores.\n",
    "\n",
    "...\n",
    "\n",
    "They scored roughly .37 and .40; the test was actually a little higher than the train, which is just a result of the split (random chance.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.4116271330202401 0.3303701838274501\n"
    }
   ],
   "source": [
    "linear = LinearRegression().fit(X_train['HR%_1'].to_frame(), y_train)\n",
    "\n",
    "print(linear.score(X_train['HR%_1'].to_frame(), y_train),\n",
    "    linear.score(X_test['HR%_1'].to_frame(), y_test)) ##rough result: .35 and .39 (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.5610194416601278 0.4289615694265221\n0.5334230008827752 0.464247907011741\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha = .001).fit(X_train,y_train)\n",
    "#cols = ['maxEV_1', 'Barrels_1', 'HardHit_1','HardHit%_1']\n",
    "linear.fit(X_train,y_train)\n",
    "print(linear.score(X_train, y_train),\n",
    "    linear.score(X_test, y_test))\n",
    "print(lasso.score(X_train, y_train),\n",
    "    lasso.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.039703346437611926\n1B_1      :  -0.033322\n2B_1      :  0.015486\n3B_1      :  -0.008434\nHR_1      :  0.114921\nBB_1      :  0.004539\nSO_1      :  0.014939\nHBP_1     :  -0.010778\nSH_1      :  -0.120601\nGDP_1     :  -0.015971\nSB_1      :  -0.011189\nCS_1      :  -0.007599\n"
    }
   ],
   "source": [
    "print(lasso.intercept_)\n",
    "for e in list(zip(X_train.columns,lasso.coef_)):\n",
    "    if e[1] != 0:\n",
    "        print('{:10}:  {:.6f}'.format(e[0],e[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "##a simple function for checking out a model\n",
    "\n",
    "def quick_check(model, data, target, random_seed=1234):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, random_state = random_seed)\n",
    "    model.fit(X_train,y_train)\n",
    "    print(\"Model train score:\\n   {}\".format(model.score(X_train,y_train)))\n",
    "    print(\"Model test score:\\n   {}\".format(model.score(X_test,y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hmmm...\n",
    "\n",
    "The above cell show some of the usual linear regression perversion: R_1 and RBI_1 have non-zero coefs while HR_1 is 0!\n",
    "\n",
    "Let's try a minimal set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model train score:\n   0.5307408461268874\nModel test score:\n   0.49399582510083195\n\nModel train score:\n   0.423557079333597\nModel test score:\n   0.3757625222523765\n\nModel train score:\n   0.5193259868530453\nModel test score:\n   0.4916715234538037\n\n"
    }
   ],
   "source": [
    "#quick_check(lasso,data,target)\n",
    "#print(data.columns)\n",
    "#print(statcast_cols)\n",
    "#print(standard_cols)\n",
    "#print(data.columns)\n",
    "x = [x+'_1' for x in standard_cols if x not in ['PA','Events']]\n",
    "x = x + [x+'%_1' for x in standard_cols if x not in ['PA','Events']]\n",
    "x = data[x]\n",
    "y = [x+'_1' for x in statcast_cols if x not in ['PA','Events']]\n",
    "y = data[y]\n",
    "#quick_check(linear, x, target)\n",
    "#print(x.head())\n",
    "quick_check(lasso, data, target)\n",
    "quick_check(lasso, x, target)\n",
    "quick_check(lasso, y, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model train score:\n   0.5255423014372425\nModel test score:\n   0.486244126242353\n\nModel train score:\n   0.45610687258592164\nModel test score:\n   0.40571036378810654\n\nModel train score:\n   0.5113419993721178\nModel test score:\n   0.4780409837273507\n\n0.49577206537676527\n\n0.049924336145080975\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('EV_1', 0.0),\n ('maxEV_1', 0.004899862445949801),\n ('LA_1', 0.0),\n ('Barrels_1', -0.0),\n ('Barrel%_1', 0.009619400997504789),\n ('HardHit_1', -0.00012384252362684936),\n ('HardHit%_1', 0.002386144745849478),\n ('cosLA_1', -0.0),\n ('sinLA_1', 0.0),\n ('EV_x_1', 0.0),\n ('EV_y_1', 0.0),\n ('Hangtime_1', 0.0),\n ('Distance_1', 0.004674760649049382),\n ('LA_optimality_1', 0.0)]"
     },
     "metadata": {},
     "execution_count": 182
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from random import randint\n",
    "\n",
    "lasso_pipe = Pipeline(\n",
    "    steps=[('scaler',scaler),\n",
    "        #('poly',PolynomialFeatures(degree=2)),\n",
    "        ('lasso',lasso)\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "lasso.alpha = .001\n",
    "quick_check(lasso_pipe, data, target)\n",
    "quick_check(lasso_pipe, x, target)\n",
    "quick_check(lasso_pipe, y, target)\n",
    "\n",
    "data1 = y\n",
    "z = 0\n",
    "times = 500\n",
    "for i in range(times):\n",
    "    rand = randint(1,100_000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data1,target)\n",
    "    lasso_pipe.fit(X_train,y_train)\n",
    "    z += lasso_pipe.score(X_test, y_test)\n",
    "print(z/times)\n",
    "\n",
    "lasso.fit(scaler.fit_transform(y),target)\n",
    "print('\\n'+str(lasso.intercept_))\n",
    "list(zip(y.columns, lasso.coef_))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refelcting on results so far   \n",
    "\n",
    "Here are the results of the above cell, run with data1 = x, y, data:\n",
    "\n",
    "```\n",
    "data 0.49717945803508745\n",
    "\n",
    "y 0.49779010748919456\n",
    "\n",
    "x 0.42453997365151097\n",
    "```\n",
    "\n",
    "What does this imply? For the available data, statcast data is a better predictor of future homeruns than past standard baseball data. The union of those two data sets doesn't outperform statcast alone.\n",
    "\n",
    "This suggests that there's a lot packed into the statcast data.\n",
    "\n",
    "I'm curious about whether a different model could get a higher score. (Earlier testing suggests that Lasso is very strong for this process.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model train score:\n   0.8192867097521981\nModel test score:\n   0.4697349737781925\n\nModel train score:\n   0.7492420454335325\nModel test score:\n   0.4289051515414324\n\nModel train score:\n   0.5708625015227997\nModel test score:\n   0.41917436654198914\n\nModel train score:\n   0.5468818111980864\nModel test score:\n   0.4105303429713306\n\n"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "boosting = GradientBoostingRegressor(n_estimators=100)\n",
    "\n",
    "quick_check(boosting, data, target)\n",
    "quick_check(boosting, y, target)\n",
    "##major overfit\n",
    "\n",
    "boosting.n_estimators = 15\n",
    "quick_check(boosting, data, target)\n",
    "quick_check(boosting, y, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(estimator=MLPRegressor(hidden_layer_sizes=[4], solver='lbfgs'),\n             param_grid={'activation': ['identity', 'logistic', 'tanh',\n                                        'relu']})"
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#MLPRegressor? There is almost certainly too little data. \n",
    "\n",
    "mlp = MLPRegressor(solver = 'lbfgs',hidden_layer_sizes=[4])\n",
    "\n",
    "layers = {'hidden_layer_sizes': [4,10,15,20,30]}\n",
    "alpha = {'alpha': [.0001,.001,.01,.1,1]}\n",
    "active = {'activation': ['identity', 'logistic', 'tanh', 'relu']}\n",
    "\n",
    "grid = GridSearchCV(mlp, param_grid=active)\n",
    "\n",
    "grid.fit(y,target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'mean_fit_time': array([0.12659855, 0.01640606, 0.01120844, 0.05272746]),\n 'std_fit_time': array([0.05765833, 0.00596163, 0.00419245, 0.03874153]),\n 'mean_score_time': array([0.00272145, 0.00263338, 0.00321093, 0.00286779]),\n 'std_score_time': array([4.04260057e-05, 4.67736663e-05, 5.12629366e-04, 3.10828071e-04]),\n 'param_activation': masked_array(data=['identity', 'logistic', 'tanh', 'relu'],\n              mask=[False, False, False, False],\n        fill_value='?',\n             dtype=object),\n 'params': [{'activation': 'identity'},\n  {'activation': 'logistic'},\n  {'activation': 'tanh'},\n  {'activation': 'relu'}],\n 'split0_test_score': array([ 0.01514067, -0.90709553, -0.91081548, -0.07590882]),\n 'split1_test_score': array([-1.61544851, -0.35026086, -0.40750631,  0.10121933]),\n 'split2_test_score': array([ 0.16315358, -0.00115373, -0.001028  , -0.00501897]),\n 'split3_test_score': array([ 0.27187935, -0.37182163, -0.35151315, -0.35332221]),\n 'split4_test_score': array([ -0.29948404,  -2.52358759, -19.38434368,  -1.2081617 ]),\n 'mean_test_score': array([-0.29295179, -0.83078387, -4.21104132, -0.30823848]),\n 'std_test_score': array([0.68862581, 0.89456613, 7.59220183, 0.47444055]),\n 'rank_test_score': array([1, 3, 4, 2], dtype=int32)}"
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Check\n",
    "\n",
    "We know that an optimum launch angle for distance is more like 30 degrees than 45 degrees. Drag reduces velocity and that means that a ball hit at 45 degrees tends to stall.\n",
    "\n",
    "Let's add a feature that's maximized when launch angle is 30 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "la_opt = df[['Name','Season','Events','playerid','EV','LA','HR%']]\n",
    "angles = [16+x for x in [1,2,3,4,5,6]]\n",
    "for a in angles:\n",
    "    opt = np.cos((la_opt['LA'] - a)/180*np.pi)**2\n",
    "    la_opt['ang_'+str(a)] = opt\n",
    "    la_opt['ang*EV_'+str(a)] = opt*la_opt['EV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             Season    Events  playerid        EV        LA       HR%  \\\nSeason     1.000000 -0.069817  0.223594  0.257816  0.085847  0.108926   \nEvents    -0.069817  1.000000  0.053294  0.154813  0.002914  0.087148   \nplayerid   0.223594  0.053294  1.000000  0.095406  0.057803  0.108253   \nEV         0.257816  0.154813  0.095406  1.000000  0.081934  0.612653   \nLA         0.085847  0.002914  0.057803  0.081934  1.000000  0.429745   \nHR%        0.108926  0.087148  0.108253  0.612653  0.429745  1.000000   \nang_17     0.070521  0.033103  0.083048  0.069731  0.847392  0.349038   \nang*EV_17  0.252030  0.146987  0.121707  0.881222  0.471043  0.686294   \nang_18     0.074487  0.028985  0.080651  0.073168  0.890094  0.369581   \nang*EV_18  0.248569  0.141037  0.121614  0.850751  0.535728  0.693869   \nang_19     0.077121  0.025720  0.078433  0.075409  0.918020  0.383308   \nang*EV_19  0.244174  0.134878  0.120924  0.818617  0.592458  0.697422   \nang_20     0.078945  0.023099  0.076471  0.076930  0.937053  0.392866   \nang*EV_20  0.239160  0.128692  0.119788  0.785918  0.641832  0.697810   \nang_21     0.080255  0.020962  0.074760  0.078002  0.950509  0.399768   \nang*EV_21  0.233782  0.122615  0.118338  0.753474  0.684598  0.695793   \nang_22     0.081225  0.019190  0.073270  0.078782  0.960325  0.404912   \nang*EV_22  0.228236  0.116739  0.116677  0.721858  0.721549  0.692004   \n\n             ang_17  ang*EV_17    ang_18  ang*EV_18    ang_19  ang*EV_19  \\\nSeason     0.070521   0.252030  0.074487   0.248569  0.077121   0.244174   \nEvents     0.033103   0.146987  0.028985   0.141037  0.025720   0.134878   \nplayerid   0.083048   0.121707  0.080651   0.121614  0.078433   0.120924   \nEV         0.069731   0.881222  0.073168   0.850751  0.075409   0.818617   \nLA         0.847392   0.471043  0.890094   0.535728  0.918020   0.592458   \nHR%        0.349038   0.686294  0.369581   0.693869  0.383308   0.697422   \nang_17     1.000000   0.532836  0.996261   0.581411  0.988466   0.623056   \nang*EV_17  0.532836   1.000000  0.534003   0.997194  0.532229   0.989690   \nang_18     0.996261   0.534003  1.000000   0.586225  0.997854   0.631204   \nang*EV_18  0.581411   0.997194  0.586225   1.000000  0.586954   0.997636   \nang_19     0.988466   0.532229  0.997854   0.586954  1.000000   0.634236   \nang*EV_19  0.623056   0.989690  0.631204   0.997636  0.634236   1.000000   \nang_20     0.979451   0.529263  0.993214   0.585777  0.998697   0.634712   \nang*EV_20  0.658455   0.978746  0.669625   0.991353  0.674755   0.998027   \nang_21     0.970413   0.525901  0.987645   0.583739  0.995786   0.633904   \nang*EV_21  0.688371   0.965418  0.702264   0.982227  0.709295   0.992804   \nang_22     0.961833   0.522507  0.981879   0.581354  0.992180   0.632461   \nang*EV_22  0.713562   0.950551  0.729900   0.971134  0.738647   0.985231   \n\n             ang_20  ang*EV_20    ang_21  ang*EV_21    ang_22  ang*EV_22  \nSeason     0.078945   0.239160  0.080255   0.233782  0.081225   0.228236  \nEvents     0.023099   0.128692  0.020962   0.122615  0.019190   0.116739  \nplayerid   0.076471   0.119788  0.074760   0.118338  0.073270   0.116677  \nEV         0.076930   0.785918  0.078002   0.753474  0.078782   0.721858  \nLA         0.937053   0.641832  0.950509   0.684598  0.960325   0.721549  \nHR%        0.392866   0.697810  0.399768   0.695793  0.404912   0.692004  \nang_17     0.979451   0.658455  0.970413   0.688371  0.961833   0.713562  \nang*EV_17  0.529263   0.978746  0.525901   0.965418  0.522507   0.950551  \nang_18     0.993214   0.669625  0.987645   0.702264  0.981879   0.729900  \nang*EV_18  0.585777   0.991353  0.583739   0.982227  0.581354   0.971134  \nang_19     0.998697   0.674755  0.995786   0.709295  0.992180   0.738647  \nang*EV_19  0.634712   0.998027  0.633904   0.992804  0.632461   0.985231  \nang_20     1.000000   0.676746  0.999168   0.712664  0.997256   0.743266  \nang*EV_20  0.676746   1.000000  0.677069   0.998364  0.676498   0.994038  \nang_21     0.999168   0.677069  1.000000   0.714022  0.999445   0.745566  \nang*EV_21  0.712664   0.998364  0.714022   1.000000  0.714250   0.998646  \nang_22     0.997256   0.676498  0.999445   0.714250  1.000000   0.746524  \nang*EV_22  0.743266   0.994038  0.745566   0.998646  0.746524   1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Season</th>\n      <th>Events</th>\n      <th>playerid</th>\n      <th>EV</th>\n      <th>LA</th>\n      <th>HR%</th>\n      <th>ang_17</th>\n      <th>ang*EV_17</th>\n      <th>ang_18</th>\n      <th>ang*EV_18</th>\n      <th>ang_19</th>\n      <th>ang*EV_19</th>\n      <th>ang_20</th>\n      <th>ang*EV_20</th>\n      <th>ang_21</th>\n      <th>ang*EV_21</th>\n      <th>ang_22</th>\n      <th>ang*EV_22</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Season</th>\n      <td>1.000000</td>\n      <td>-0.069817</td>\n      <td>0.223594</td>\n      <td>0.257816</td>\n      <td>0.085847</td>\n      <td>0.108926</td>\n      <td>0.070521</td>\n      <td>0.252030</td>\n      <td>0.074487</td>\n      <td>0.248569</td>\n      <td>0.077121</td>\n      <td>0.244174</td>\n      <td>0.078945</td>\n      <td>0.239160</td>\n      <td>0.080255</td>\n      <td>0.233782</td>\n      <td>0.081225</td>\n      <td>0.228236</td>\n    </tr>\n    <tr>\n      <th>Events</th>\n      <td>-0.069817</td>\n      <td>1.000000</td>\n      <td>0.053294</td>\n      <td>0.154813</td>\n      <td>0.002914</td>\n      <td>0.087148</td>\n      <td>0.033103</td>\n      <td>0.146987</td>\n      <td>0.028985</td>\n      <td>0.141037</td>\n      <td>0.025720</td>\n      <td>0.134878</td>\n      <td>0.023099</td>\n      <td>0.128692</td>\n      <td>0.020962</td>\n      <td>0.122615</td>\n      <td>0.019190</td>\n      <td>0.116739</td>\n    </tr>\n    <tr>\n      <th>playerid</th>\n      <td>0.223594</td>\n      <td>0.053294</td>\n      <td>1.000000</td>\n      <td>0.095406</td>\n      <td>0.057803</td>\n      <td>0.108253</td>\n      <td>0.083048</td>\n      <td>0.121707</td>\n      <td>0.080651</td>\n      <td>0.121614</td>\n      <td>0.078433</td>\n      <td>0.120924</td>\n      <td>0.076471</td>\n      <td>0.119788</td>\n      <td>0.074760</td>\n      <td>0.118338</td>\n      <td>0.073270</td>\n      <td>0.116677</td>\n    </tr>\n    <tr>\n      <th>EV</th>\n      <td>0.257816</td>\n      <td>0.154813</td>\n      <td>0.095406</td>\n      <td>1.000000</td>\n      <td>0.081934</td>\n      <td>0.612653</td>\n      <td>0.069731</td>\n      <td>0.881222</td>\n      <td>0.073168</td>\n      <td>0.850751</td>\n      <td>0.075409</td>\n      <td>0.818617</td>\n      <td>0.076930</td>\n      <td>0.785918</td>\n      <td>0.078002</td>\n      <td>0.753474</td>\n      <td>0.078782</td>\n      <td>0.721858</td>\n    </tr>\n    <tr>\n      <th>LA</th>\n      <td>0.085847</td>\n      <td>0.002914</td>\n      <td>0.057803</td>\n      <td>0.081934</td>\n      <td>1.000000</td>\n      <td>0.429745</td>\n      <td>0.847392</td>\n      <td>0.471043</td>\n      <td>0.890094</td>\n      <td>0.535728</td>\n      <td>0.918020</td>\n      <td>0.592458</td>\n      <td>0.937053</td>\n      <td>0.641832</td>\n      <td>0.950509</td>\n      <td>0.684598</td>\n      <td>0.960325</td>\n      <td>0.721549</td>\n    </tr>\n    <tr>\n      <th>HR%</th>\n      <td>0.108926</td>\n      <td>0.087148</td>\n      <td>0.108253</td>\n      <td>0.612653</td>\n      <td>0.429745</td>\n      <td>1.000000</td>\n      <td>0.349038</td>\n      <td>0.686294</td>\n      <td>0.369581</td>\n      <td>0.693869</td>\n      <td>0.383308</td>\n      <td>0.697422</td>\n      <td>0.392866</td>\n      <td>0.697810</td>\n      <td>0.399768</td>\n      <td>0.695793</td>\n      <td>0.404912</td>\n      <td>0.692004</td>\n    </tr>\n    <tr>\n      <th>ang_17</th>\n      <td>0.070521</td>\n      <td>0.033103</td>\n      <td>0.083048</td>\n      <td>0.069731</td>\n      <td>0.847392</td>\n      <td>0.349038</td>\n      <td>1.000000</td>\n      <td>0.532836</td>\n      <td>0.996261</td>\n      <td>0.581411</td>\n      <td>0.988466</td>\n      <td>0.623056</td>\n      <td>0.979451</td>\n      <td>0.658455</td>\n      <td>0.970413</td>\n      <td>0.688371</td>\n      <td>0.961833</td>\n      <td>0.713562</td>\n    </tr>\n    <tr>\n      <th>ang*EV_17</th>\n      <td>0.252030</td>\n      <td>0.146987</td>\n      <td>0.121707</td>\n      <td>0.881222</td>\n      <td>0.471043</td>\n      <td>0.686294</td>\n      <td>0.532836</td>\n      <td>1.000000</td>\n      <td>0.534003</td>\n      <td>0.997194</td>\n      <td>0.532229</td>\n      <td>0.989690</td>\n      <td>0.529263</td>\n      <td>0.978746</td>\n      <td>0.525901</td>\n      <td>0.965418</td>\n      <td>0.522507</td>\n      <td>0.950551</td>\n    </tr>\n    <tr>\n      <th>ang_18</th>\n      <td>0.074487</td>\n      <td>0.028985</td>\n      <td>0.080651</td>\n      <td>0.073168</td>\n      <td>0.890094</td>\n      <td>0.369581</td>\n      <td>0.996261</td>\n      <td>0.534003</td>\n      <td>1.000000</td>\n      <td>0.586225</td>\n      <td>0.997854</td>\n      <td>0.631204</td>\n      <td>0.993214</td>\n      <td>0.669625</td>\n      <td>0.987645</td>\n      <td>0.702264</td>\n      <td>0.981879</td>\n      <td>0.729900</td>\n    </tr>\n    <tr>\n      <th>ang*EV_18</th>\n      <td>0.248569</td>\n      <td>0.141037</td>\n      <td>0.121614</td>\n      <td>0.850751</td>\n      <td>0.535728</td>\n      <td>0.693869</td>\n      <td>0.581411</td>\n      <td>0.997194</td>\n      <td>0.586225</td>\n      <td>1.000000</td>\n      <td>0.586954</td>\n      <td>0.997636</td>\n      <td>0.585777</td>\n      <td>0.991353</td>\n      <td>0.583739</td>\n      <td>0.982227</td>\n      <td>0.581354</td>\n      <td>0.971134</td>\n    </tr>\n    <tr>\n      <th>ang_19</th>\n      <td>0.077121</td>\n      <td>0.025720</td>\n      <td>0.078433</td>\n      <td>0.075409</td>\n      <td>0.918020</td>\n      <td>0.383308</td>\n      <td>0.988466</td>\n      <td>0.532229</td>\n      <td>0.997854</td>\n      <td>0.586954</td>\n      <td>1.000000</td>\n      <td>0.634236</td>\n      <td>0.998697</td>\n      <td>0.674755</td>\n      <td>0.995786</td>\n      <td>0.709295</td>\n      <td>0.992180</td>\n      <td>0.738647</td>\n    </tr>\n    <tr>\n      <th>ang*EV_19</th>\n      <td>0.244174</td>\n      <td>0.134878</td>\n      <td>0.120924</td>\n      <td>0.818617</td>\n      <td>0.592458</td>\n      <td>0.697422</td>\n      <td>0.623056</td>\n      <td>0.989690</td>\n      <td>0.631204</td>\n      <td>0.997636</td>\n      <td>0.634236</td>\n      <td>1.000000</td>\n      <td>0.634712</td>\n      <td>0.998027</td>\n      <td>0.633904</td>\n      <td>0.992804</td>\n      <td>0.632461</td>\n      <td>0.985231</td>\n    </tr>\n    <tr>\n      <th>ang_20</th>\n      <td>0.078945</td>\n      <td>0.023099</td>\n      <td>0.076471</td>\n      <td>0.076930</td>\n      <td>0.937053</td>\n      <td>0.392866</td>\n      <td>0.979451</td>\n      <td>0.529263</td>\n      <td>0.993214</td>\n      <td>0.585777</td>\n      <td>0.998697</td>\n      <td>0.634712</td>\n      <td>1.000000</td>\n      <td>0.676746</td>\n      <td>0.999168</td>\n      <td>0.712664</td>\n      <td>0.997256</td>\n      <td>0.743266</td>\n    </tr>\n    <tr>\n      <th>ang*EV_20</th>\n      <td>0.239160</td>\n      <td>0.128692</td>\n      <td>0.119788</td>\n      <td>0.785918</td>\n      <td>0.641832</td>\n      <td>0.697810</td>\n      <td>0.658455</td>\n      <td>0.978746</td>\n      <td>0.669625</td>\n      <td>0.991353</td>\n      <td>0.674755</td>\n      <td>0.998027</td>\n      <td>0.676746</td>\n      <td>1.000000</td>\n      <td>0.677069</td>\n      <td>0.998364</td>\n      <td>0.676498</td>\n      <td>0.994038</td>\n    </tr>\n    <tr>\n      <th>ang_21</th>\n      <td>0.080255</td>\n      <td>0.020962</td>\n      <td>0.074760</td>\n      <td>0.078002</td>\n      <td>0.950509</td>\n      <td>0.399768</td>\n      <td>0.970413</td>\n      <td>0.525901</td>\n      <td>0.987645</td>\n      <td>0.583739</td>\n      <td>0.995786</td>\n      <td>0.633904</td>\n      <td>0.999168</td>\n      <td>0.677069</td>\n      <td>1.000000</td>\n      <td>0.714022</td>\n      <td>0.999445</td>\n      <td>0.745566</td>\n    </tr>\n    <tr>\n      <th>ang*EV_21</th>\n      <td>0.233782</td>\n      <td>0.122615</td>\n      <td>0.118338</td>\n      <td>0.753474</td>\n      <td>0.684598</td>\n      <td>0.695793</td>\n      <td>0.688371</td>\n      <td>0.965418</td>\n      <td>0.702264</td>\n      <td>0.982227</td>\n      <td>0.709295</td>\n      <td>0.992804</td>\n      <td>0.712664</td>\n      <td>0.998364</td>\n      <td>0.714022</td>\n      <td>1.000000</td>\n      <td>0.714250</td>\n      <td>0.998646</td>\n    </tr>\n    <tr>\n      <th>ang_22</th>\n      <td>0.081225</td>\n      <td>0.019190</td>\n      <td>0.073270</td>\n      <td>0.078782</td>\n      <td>0.960325</td>\n      <td>0.404912</td>\n      <td>0.961833</td>\n      <td>0.522507</td>\n      <td>0.981879</td>\n      <td>0.581354</td>\n      <td>0.992180</td>\n      <td>0.632461</td>\n      <td>0.997256</td>\n      <td>0.676498</td>\n      <td>0.999445</td>\n      <td>0.714250</td>\n      <td>1.000000</td>\n      <td>0.746524</td>\n    </tr>\n    <tr>\n      <th>ang*EV_22</th>\n      <td>0.228236</td>\n      <td>0.116739</td>\n      <td>0.116677</td>\n      <td>0.721858</td>\n      <td>0.721549</td>\n      <td>0.692004</td>\n      <td>0.713562</td>\n      <td>0.950551</td>\n      <td>0.729900</td>\n      <td>0.971134</td>\n      <td>0.738647</td>\n      <td>0.985231</td>\n      <td>0.743266</td>\n      <td>0.994038</td>\n      <td>0.745566</td>\n      <td>0.998646</td>\n      <td>0.746524</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "source": [
    "la_opt.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.5183386220544914"
     },
     "metadata": {},
     "execution_count": 200
    }
   ],
   "source": [
    "y['LA*EV_1'] = y['LA_optimality_1']*y['EV_1']\n",
    "X_train,X_test,y_train,y_test = train_test_split(y,target)\n",
    "lasso.fit(X_train,y_train)\n",
    "lasso.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(893, 15)"
     },
     "metadata": {},
     "execution_count": 197
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}