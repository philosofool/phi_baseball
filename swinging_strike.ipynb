{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Classify Pitches as Swinging Strikes\n",
    "\n",
    "Swinging strikes are strongly correlated with pitcher effectiveness. This is likely because strikeout outs are strongly correlated with pitching effectiveness. Previous research of mine suggested that there is more variance in pitcher's swinging strikeout is more projectable (i.e., has higher $r^2$) from season to season than called strikeout rate. Futhermore, the majority of strikeouts are swinging strikeouts.\n",
    "\n",
    "The goal of this project is to determine whether data about pitch movement, velocity, release point and location relative to the strike zone is sufficient to classify pitches as swinging strikes. If so, this suggests that pitches induce swinging strikes. It is possible that additional factors involving the pitcher, game state, and the batter are significant influences on whether a pitch will result in a swinging strike.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/statcast_dumps/statcast2017.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'pitch_type', 'game_date', 'release_speed', 'release_pos_x',\n",
       "       'release_pos_z', 'player_name', 'batter', 'pitcher', 'events',\n",
       "       'description', 'zone', 'des', 'game_type', 'stand', 'p_throws',\n",
       "       'home_team', 'away_team', 'type', 'hit_location', 'bb_type', 'balls',\n",
       "       'strikes', 'game_year', 'pfx_x', 'pfx_z', 'plate_x', 'plate_z', 'on_3b',\n",
       "       'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot', 'hc_x',\n",
       "       'hc_y', 'fielder_2', 'sv_id', 'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az',\n",
       "       'sz_top', 'sz_bot', 'hit_distance_sc', 'launch_speed', 'launch_angle',\n",
       "       'effective_speed', 'release_spin_rate', 'release_extension', 'game_pk',\n",
       "       'pitcher.1', 'fielder_2.1', 'fielder_3', 'fielder_4', 'fielder_5',\n",
       "       'fielder_6', 'fielder_7', 'fielder_8', 'fielder_9', 'release_pos_y',\n",
       "       'estimated_ba_using_speedangle', 'estimated_woba_using_speedangle',\n",
       "       'woba_value', 'woba_denom', 'babip_value', 'iso_value',\n",
       "       'launch_speed_angle', 'at_bat_number', 'pitch_number', 'pitch_name',\n",
       "       'home_score', 'away_score', 'bat_score', 'fld_score', 'post_away_score',\n",
       "       'post_home_score', 'post_bat_score', 'post_fld_score',\n",
       "       'if_fielding_alignment', 'of_fielding_alignment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deprecated = ['spin_dir','spin_rate_deprecated',\n",
    "              'break_angle_deprecated','break_length_deprecated',\n",
    "              'tfs_deprecated', 'tfs_zulu_deprecated','umpire']\n",
    "df.drop(labels=deprecated,axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Working...\")\n",
    "df1 = pd.read_csv('data/statcast_dumps/statcast2018.csv').drop('Unnamed: 0', axis=1)\n",
    "df1.drop(labels=deprecated,axis=1, inplace=True)\n",
    "print(\"Working...\")\n",
    "df2 = pd.read_csv('data/statcast_dumps/statcast2019.csv').drop('Unnamed: 0', axis=1)\n",
    "df2.drop(labels=deprecated,axis=1, inplace=True)\n",
    "print(\"Working...\")\n",
    "df3 = pd.read_csv('data/statcast_dumps/statcast2020.csv').drop('Unnamed: 0', axis=1)\n",
    "df3.drop(labels=deprecated,axis=1, inplace=True)\n",
    "print(\"Working...\")\n",
    "df = pd.concat([df,df1,df2,df3])\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del(df1)\n",
    "del(df2)\n",
    "del(df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7655, 83)\n",
      "index                        0\n",
      "pitch_type               15340\n",
      "game_date                    0\n",
      "release_speed            14912\n",
      "release_pos_x            12166\n",
      "                         ...  \n",
      "post_home_score              0\n",
      "post_bat_score               0\n",
      "post_fld_score               0\n",
      "if_fielding_alignment    11358\n",
      "of_fielding_alignment    11358\n",
      "Length: 83, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2355353, 83)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df.drop('Unnamed: 0.1',axis=1,inplace=True)\n",
    "except:\n",
    "    pass\n",
    "print(df.dropna().shape)\n",
    "print(df.isna().sum())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's a swinging strike?\n",
    "\n",
    "The question isn't as simple as it sounds. A foul ball with fewer than 2 strikes has the effect of a swinging strike (unless it's also a popup); it's worse than not swinging at a ball out of the zone and no better than a called strike. With 2 strikes, a foul ball is worse than swinging at a ball out of the zone but better than a called strike. \n",
    "\n",
    "_I'm going to stipulate that a foul ball is not a swinging strike, a foul tip is._ This is mostly for simplicity at present, but if this were a multiple classificaiton problem, I would regard foul balls as a separate class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_swinging_strike(row):\n",
    "    if row['description'] in ['swinging_strike','swinging_strike_blocked','foul_tip']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def is_swinging_strike2(row):\n",
    "    if row['description'] == 'swinging_strike':\n",
    "        return True\n",
    "    elif row['description'] == 'swinging_strike_blocked':\n",
    "        return True\n",
    "    elif row['description'] == 'foul_tip':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def is_swinging_strike3(col):\n",
    "    '''\n",
    "    Let's just do pd.series.apply...\n",
    "    '''\n",
    "    if col in ['swinging_strike','swinging_strike_blocked','foul_tip']:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the classification\n",
    "\n",
    "Wow. The kernel crashed horribly when I ran ```df['swinging_strike'] = df.apply(is_swinging_strike,axis=1)```. I used the cell below to find a much faster method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3903791904449463\n",
      "0.7085263729095459\n",
      "0.003505229949951172\n"
     ]
    }
   ],
   "source": [
    "## This was deadly slow. Like, it crashed the kernel.\n",
    "#df['swinging_strike'] = df.apply(is_swinging_strike,axis=1)\n",
    "#df.columns\n",
    "\n",
    "##Let's see if we can optimize.\n",
    "import time\n",
    "temp = df.iloc[0:10000].copy()##a much smaller dataframe for testing time.\n",
    "start = time.time()\n",
    "temp.apply(is_swinging_strike,axis=1)\n",
    "print(time.time() - start)\n",
    "start = time.time()\n",
    "temp.apply(is_swinging_strike2,axis=1)\n",
    "print(time.time() - start)\n",
    "start = time.time()\n",
    "temp['description'].apply(is_swinging_strike3)\n",
    "print(time.time() - start)\n",
    "###and we have a winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['swinging_strike'] = df['description'].apply(is_swinging_strike3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time to select the data that we're using for prediciton.\n",
    "## Statcast data documentation at https://baseballsavant.mlb.com/csv-docs\n",
    "\n",
    "#for e in df.columns:\n",
    "#    print(\"'\"+e+\"',\")##copy and paste output, then comment out.\n",
    "#print(df.columns)\n",
    "\n",
    "physical_data = ['release_speed',\n",
    " 'release_pos_x',\n",
    " 'release_pos_z',\n",
    " 'pfx_x',\n",
    " 'pfx_z',\n",
    " 'plate_x',\n",
    " 'plate_z',\n",
    " 'vx0',\n",
    " 'vy0',\n",
    " 'vz0',\n",
    " 'ax',\n",
    " 'ay',\n",
    " 'az',\n",
    " 'release_pos_y',\n",
    " 'release_spin_rate'\n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2304729, 84)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=physical_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data = df.dropna(subset=physical_data)\n",
    "\n",
    "## I later found that using more than 5000 samples from the data provided no performance improvements\n",
    "## but came with a significant training time cost.\n",
    "## Hence, training size will be just 30_000, which leaves room to find performance gains.\n",
    "## We can re-test on the whole set later\n",
    "\n",
    "X_train, X_hold, y_train, y_hold = train_test_split(data[physical_data],\n",
    "                                                    data['swinging_strike'], train_size = 30_000, test_size=10_000)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_hold, y_hold, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 15)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic = Pipeline([('scaler', StandardScaler()), ('logistic_regression', LogisticRegression(max_iter=400))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "try:\n",
    "    temp = open('logistic.pickle','rb')\n",
    "    logistic = pickle.load(temp)\n",
    "    temp.close()\n",
    "    raise Exception ##uncomment to force\n",
    "except:\n",
    "    logistic.fit(X_train,y_train)\n",
    "    pickle.dump(logistic,open('logistic.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8866\n",
      "0.8866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy = DummyClassifier(strategy='most_frequent').fit(X_train,y_train)\n",
    "print(dummy.score(X_dev,y_dev))\n",
    "print(logistic.score(X_dev,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4433    0]\n",
      " [ 567    0]]\n",
      "[[4433    0]\n",
      " [ 567    0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_dev,logistic.predict(X_dev)))\n",
    "print(confusion_matrix(y_dev,dummy.predict(X_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wow.\n",
    "\n",
    "The logistic classifier is easily the worst classifier I have ever seen. It's slightly worse than the dummy classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forest_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forest_clf.score(X_dev,y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_mlp_clf = MLPClassifier(activation='tanh', hidden_layer_sizes=(4),\n",
    "                               alpha = 0,\n",
    "                               solver='sgd',\n",
    "                               max_iter=2000,\n",
    "                               learning_rate_init=.03\n",
    "                              )\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('mlp',simple_mlp_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pipe = pickle.load(open('pipe.pickle','rb'))\n",
    "    #raise Exception ##uncomment to force fitting\n",
    "except:\n",
    "    print(\"No such pickle. Fitting pipe and pickling.\")\n",
    "    pipe.fit(X_train,y_train)\n",
    "    pickle.dump(pipe,open('pipe.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:\n",
      "0.8804\n",
      "Dev   score:\n",
      "0.8866\n",
      "Dev Confusion matrix:\n",
      "[[4433    0]\n",
      " [ 567    0]]\n"
     ]
    }
   ],
   "source": [
    "def quick_analysis(model):\n",
    "    print(\"Train score:\\n{:.4f}\".format(model.score(X_train,y_train)))\n",
    "    print(\"Dev   score:\\n{}\".format(model.score(X_dev,y_dev)))\n",
    "    print(\"Dev Confusion matrix:\\n{}\".format(confusion_matrix(y_dev,model.predict(X_dev))))\n",
    "quick_analysis(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oooof\n",
    "\n",
    "This surprises me. Is there really nothing that allows us to better predict the result of a pitch than assuming the most frequent class?\n",
    "\n",
    "Let's increase our number of units in the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_mlp_clf = MLPClassifier(activation='tanh', hidden_layer_sizes=(9),\n",
    "                               alpha = 0,\n",
    "                               solver='sgd',\n",
    "                               max_iter=2000,\n",
    "                               learning_rate_init=.03\n",
    "                              )\n",
    "pipe_large = Pipeline([('scaler', StandardScaler()),('mlp',simple_mlp_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pipe_large = pickle.load(open('pipe_large.pickle','rb'))\n",
    "    #raise Exception ##uncomment to force                        \n",
    "except:\n",
    "    pipe_large.fit(X_train,y_train)\n",
    "    pickle.dump(pipe_large,open('pipe_large.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:\n",
      "0.8804\n",
      "Dev   score:\n",
      "0.8866\n",
      "Dev Confusion matrix:\n",
      "[[4433    0]\n",
      " [ 567    0]]\n"
     ]
    }
   ],
   "source": [
    "quick_analysis(pipe_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_layer_mlp_clf = MLPClassifier(activation='tanh', hidden_layer_sizes=(8,4),\n",
    "                               alpha = 0,\n",
    "                               solver='sgd',\n",
    "                               max_iter=2000,\n",
    "                               learning_rate_init=.03\n",
    "                              )\n",
    "two_layer_pipe = Pipeline([('scaler', StandardScaler()),('mlp',two_layer_mlp_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    two_layer_pipe = pickle.load(open('two_layer_pipe.pickle','rb'))\n",
    "    #two_layer_pipe.predict(X_dev.iloc[0])\n",
    "    #raise Exception ##uncomment to force fitting\n",
    "except:\n",
    "    print(\"Failed to open two_layer_pipe. Fitting and pickling...\")\n",
    "    two_layer_pipe.fit(X_train,y_train)\n",
    "    pickle.dump(two_layer_pipe,open('two_layer_pipe.pickle','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('mlp',\n",
      "                 MLPClassifier(activation='tanh', alpha=0,\n",
      "                               hidden_layer_sizes=(8, 4),\n",
      "                               learning_rate_init=0.03, max_iter=2000,\n",
      "                               solver='sgd'))])\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('logistic_regression', LogisticRegression(max_iter=400))])\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('mlp',\n",
      "                 MLPClassifier(activation='tanh', alpha=0, hidden_layer_sizes=9,\n",
      "                               learning_rate_init=0.03, max_iter=2000,\n",
      "                               solver='sgd'))])\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('mlp',\n",
      "                 MLPClassifier(activation='tanh', alpha=0, hidden_layer_sizes=4,\n",
      "                               learning_rate_init=0.03, max_iter=2000,\n",
      "                               solver='sgd'))])\n"
     ]
    }
   ],
   "source": [
    "print(two_layer_pipe)\n",
    "print(logistic)\n",
    "print(pipe_large)\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rethinking model evaluation\n",
    "\n",
    "I mean, I know this could be a really hard problem, but it seems a little nuts that there's literally nothing about movement (etc.) of a pitch that wouldn't make it more likely to be a swinging strike. \n",
    "\n",
    "### This is about probabilities and classification\n",
    "\n",
    "Let's face it, no pitch is more than 50% likely to be a swinging strike. So, there's your issue. Sure, a 101 mph fastball at the top of the zone is more likely to be one, but even the best located 100mph fastballs aren't swinging strikes more than 50% of the time.\n",
    "\n",
    "We need to implement better measures of model accuracy. In particular, a model is good if it assigns higher probabilities to pitches that are actually swinging strikes. Two functions below assess the average deviation of swing strike probability from the classification.\n",
    "\n",
    "### Multiple Classification\n",
    "\n",
    "Just looking at swinging strikes is fun, but of course, the base rate of a non-swinging strike is about 7 times higher, so of course your classifier is going to favor that base rate unless there are strong swinging strike indicators.\n",
    "\n",
    "### Revisit Data\n",
    "\n",
    "What if there are some elements that I should have included which might be making things noisy? That is, maybe there's something which, if you added it, would make it easier to classify?\n",
    "\n",
    "Here's what I notice in the data that I didn't include as features:\n",
    "- **p_throws** whether the pitcher is right or left handed. This seems pretty important. Technically not physical data, but it could be noise that matters.\n",
    "- **stand** is the side of the plate that the batter is on. That seems pretty important. \n",
    "- **count** seems like it could matter. It's not physical data, though. Still, perhaps the noise comes from batters not swinging at \"tough\" pitches when they are ahead. There's an additional issue with including it, too: a pitcher who gets ahead is more likely to get swinging strikes.\n",
    "- **type** this is the classifiation of the pitch as a 'slider', 'fastball', etc. This might matter, but it also seems to be non-physical data.\n",
    "\n",
    "Let's revisit our data and see if the batter/pitcher handedness makes a difference to these classifications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##curious\n",
    "logistic_proba = logistic.predict_proba(X_train).T\n",
    "pipe_proba = pipe.predict_proba(X_train).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10057"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pipe_proba[1] > .12\n",
    "b = pipe_proba[1] > .14\n",
    "np.sum(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_standard_error(model):\n",
    "    predict = model.predict_proba(X_dev).T[1]\n",
    "    error = (y_dev.astype(int) - predict)\n",
    "    return np.sum(error*error)/len(error)\n",
    "\n",
    "def model_absolute_error(model):\n",
    "    predict = model.predict_proba(X_dev).T[1]\n",
    "    error = np.abs(y_dev.astype(int) - predict)\n",
    "    return np.sum(error)/len(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error\n",
      "0.1134\n",
      "0.2024668536420064\n",
      "0.18913982231091123\n",
      "0.1890874798571327\n",
      "0.18636042405111003\n",
      "Mean Standard Error\n",
      "0.1134\n",
      "0.09897089884541346\n",
      "0.09457206923591979\n",
      "0.09279901892412655\n",
      "0.09276316795999799\n"
     ]
    }
   ],
   "source": [
    "two_layer_pipe.predict(X_dev)\n",
    "print(\"Mean Absolute Error\")\n",
    "for model in [dummy,logistic,pipe,pipe_large,two_layer_pipe]:\n",
    "    print(model_absolute_error(model))\n",
    "print(\"Mean Standard Error\")\n",
    "for model in [dummy,logistic,pipe,pipe_large,two_layer_pipe]:\n",
    "    print(model_standard_error(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1134\n",
      "0.2024668536420064\n",
      "0.18913982231091123\n",
      "0.1890874798571327\n",
      "0.18636042405111003\n"
     ]
    }
   ],
   "source": [
    "for model in [dummy,logistic,pipe,pipe_large,two_layer_pipe]:\n",
    "    print(model_absolute_error(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'].unique()\n",
    "in_play = ['hit_into_play_score', 'hit_into_play','hit_into_play_no_out']\n",
    "swinging_strike = ['swinging_strike','swinging_strike_blocked','foul_tip']\n",
    "called_strike = ['called_strike']\n",
    "ball = ['ball', 'blocked_ball', 'hit_by_pitch']\n",
    "foul = ['foul', 'foul_pitchout']\n",
    "bunt = ['missed_bunt','foul_bunt','bunt_foul_tip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_result(x):\n",
    "    if x in in_play:\n",
    "        return 1\n",
    "    elif x in swinging_strike:\n",
    "        return 2\n",
    "    elif x in called_strike:\n",
    "        return 3\n",
    "    elif x in ball:\n",
    "        return 4\n",
    "    elif x in foul:\n",
    "        return 5\n",
    "    elif x in bunt:\n",
    "        return 6 \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "df['result'] = df['description'].apply(basic_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         2\n",
       "2         5\n",
       "3         4\n",
       "4         2\n",
       "         ..\n",
       "173854    3\n",
       "173855    1\n",
       "173856    3\n",
       "173857    1\n",
       "173858    4\n",
       "Name: result, Length: 2355353, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict = {\n",
    "    0 : 'uncategorized',\n",
    "    1 : 'in play',\n",
    "    2 : 'swinging strike',\n",
    "    3 : 'called strike',\n",
    "    4 : 'ball',\n",
    "    5 : 'foul ball',\n",
    "    6 : 'bunt'\n",
    "}\n",
    "\n",
    "\n",
    "df['result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This usually fails, seemingly because df is very big.\")\n",
    "##data2 = df.dropna(subset=physical_data)\n",
    "subset = physical_data + ['result']\n",
    "data2 = df[subset].copy()\n",
    "data2.dropna(inplace = True)\n",
    "X_train2, X_hold2, y_train2, y_hold2 = train_test_split(data2[physical_data],\n",
    "                                                    data2['result'], train_size=30_0000, test_size=10000)\n",
    "X_dev2, X_test2, y_dev2, y_test2 = train_test_split(X_hold2, y_hold2, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## max_iter= 400 did not converge and had bad results. Changed to 1000\n",
    "logistic2 = Pipeline([('scaler', StandardScaler()), ('logistic_regression', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "try:\n",
    "    logistic2 = pickle.load(open('logistic2.pickle','rb'))\n",
    "except:\n",
    "    ##FIX ME: this has not been run with max_iter = 1000.\n",
    "    logistic2.fit(X_train2,y_train2)\n",
    "    pickle.dump(logistic2,open('logistic2.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'uncategorized', 1: 'in play', 2: 'swinging strike', 3: 'called strike', 4: 'ball', 5: 'foul ball', 6: 'bunt'}\n",
      "Train score:\n",
      "0.3314\n",
      "Dev   score:\n",
      "0.3318\n",
      "Dev Confusion matrix:\n",
      "[[   0    0    0    0    2    0    0]\n",
      " [   0   29    1    9  867   11    0]\n",
      " [   0    7    0   12  559   17    0]\n",
      " [   0   21    0   23  785    4    0]\n",
      " [   0   72    0   60 1592   82    0]\n",
      " [   0   14    0   15  788   15    0]\n",
      " [   0    2    0    0   13    0    0]]\n",
      "Recall:\n",
      "uncategorized: 0.000\n",
      "in play: 0.032\n",
      "swinging strike: 0.000\n",
      "called strike: 0.028\n",
      "ball: 0.882\n",
      "foul ball: 0.018\n",
      "bunt: 0.000\n",
      "\n",
      "Precision\n",
      "uncategorized: nan\n",
      "in play: 0.200\n",
      "swinging strike: 0.000\n",
      "called strike: 0.193\n",
      "ball: 0.346\n",
      "foul ball: 0.116\n",
      "bunt: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-06c06e2c8c4b>:16: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp/x[:,i].sum()\n"
     ]
    }
   ],
   "source": [
    "def quick_analysis_multi(model):\n",
    "    print(\"Train score:\\n{:.4f}\".format(model.score(X_train2,y_train2)))\n",
    "    print(\"Dev   score:\\n{}\".format(model.score(X_dev2,y_dev2)))\n",
    "    x = confusion_matrix(y_dev2,model.predict(X_dev2))\n",
    "    print(\"Dev Confusion matrix:\\n{}\".format(x))\n",
    "    print('Recall:') \n",
    "    for i in range(x.shape[1]):\n",
    "        true_positives = x[i,i]\n",
    "        all_positives = x[i,:].sum()\n",
    "        recall = true_positives/all_positives\n",
    "        print(\"{}: {:.3f}\".format(result_dict[i],recall))\n",
    "\n",
    "    print('\\nPrecision')\n",
    "    for i in range(x.shape[1]):\n",
    "        tp = x[i,i]\n",
    "        precision = tp/x[:,i].sum()\n",
    "        print(\"{}: {:.3f}\".format(result_dict[i],precision))\n",
    "\n",
    "print(result_dict)\n",
    "quick_analysis_multi(logistic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:\n",
      "0.5174\n",
      "Dev   score:\n",
      "0.5084\n",
      "Dev Confusion matrix:\n",
      "[[   0    0    0    0    2    0    0]\n",
      " [   0  441    0  177  143  156    0]\n",
      " [   0  146    0   58  300   91    0]\n",
      " [   0  357    0  276   72  128    0]\n",
      " [   0   71    0   60 1642   33    0]\n",
      " [   0  348    0  132  169  183    0]\n",
      " [   0    3    0    3    8    1    0]]\n",
      "Recall:\n",
      "uncategorized: 0.000\n",
      "in play: 0.481\n",
      "swinging strike: 0.000\n",
      "called strike: 0.331\n",
      "ball: 0.909\n",
      "foul ball: 0.220\n",
      "bunt: 0.000\n",
      "\n",
      "Precision\n",
      "uncategorized: nan\n",
      "in play: 0.323\n",
      "swinging strike: nan\n",
      "called strike: 0.391\n",
      "ball: 0.703\n",
      "foul ball: 0.309\n",
      "bunt: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-06c06e2c8c4b>:16: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp/x[:,i].sum()\n"
     ]
    }
   ],
   "source": [
    "forest_multi_clf = RandomForestClassifier(n_estimators=40, max_depth=8)##I tried this with the default 100 estimators, trained to slow.\n",
    "forest_multi_clf.fit(X_train2,y_train2)\n",
    "quick_analysis_multi(forest_multi_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:\n",
      "0.4969\n",
      "Dev   score:\n",
      "0.4896\n",
      "Dev Confusion matrix:\n",
      "[[   0    0    0    0    2    0    0]\n",
      " [   0  358   41  262  123  133    0]\n",
      " [   0  104   61  105  252   71    2]\n",
      " [   0  295   21  300   78  139    0]\n",
      " [   0   37   64   66 1573   61    5]\n",
      " [   0  281   46  205  140  156    4]\n",
      " [   0    3    0    3    8    1    0]]\n",
      "Recall:\n",
      "uncategorized: 0.000\n",
      "in play: 0.390\n",
      "swinging strike: 0.103\n",
      "called strike: 0.360\n",
      "ball: 0.871\n",
      "foul ball: 0.188\n",
      "bunt: 0.000\n",
      "\n",
      "Precision\n",
      "uncategorized: nan\n",
      "in play: 0.332\n",
      "swinging strike: 0.262\n",
      "called strike: 0.319\n",
      "ball: 0.723\n",
      "foul ball: 0.278\n",
      "bunt: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-06c06e2c8c4b>:16: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp/x[:,i].sum()\n"
     ]
    }
   ],
   "source": [
    "## The gradient classifier takes forever to train. Let's train it on a smaller sample.\n",
    "\n",
    "X_grad, X_ignore, y_grad, y_ignore = train_test_split(X_train2,y_train2,train_size=2500)\n",
    "\n",
    "gradient_multi_clf = GradientBoostingClassifier()\n",
    "gradient_multi_clf.fit(X_grad,y_grad)\n",
    "quick_analysis_multi(gradient_multi_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_4 = MLPClassifier(activation='tanh', hidden_layer_sizes=(4),\n",
    "                               alpha = 0,\n",
    "                               solver='sgd',\n",
    "                               max_iter=5000,\n",
    "                               learning_rate_init=.03\n",
    "                              )\n",
    "\n",
    "mlp_4 = Pipeline([('scaler', StandardScaler()),('mlp', mlp_4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name = 'mlp_4.pickle'\n",
    "try:\n",
    "    #raise Exception\n",
    "    mlp_4 = pickle.load(open(clf_name,'rb'))\n",
    "except:\n",
    "    file = open(clf_name,'wb')\n",
    "    mlp_4.fit(X_train2,y_train2)\n",
    "    pickle.dump(mlp_4,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:\n",
      "0.4996\n",
      "Dev   score:\n",
      "0.4882\n",
      "Dev Confusion matrix:\n",
      "[[   0    0    0    0    2    0    0]\n",
      " [   0  469   44  130  108  166    0]\n",
      " [   0  170   53   33  249   90    0]\n",
      " [   0  359   19  176   92  187    0]\n",
      " [   0   30   59   51 1582   84    0]\n",
      " [   0  403   35   96  137  161    0]\n",
      " [   0    4    0    2    9    0    0]]\n",
      "Recall:\n",
      "uncategorized: 0.000\n",
      "in play: 0.511\n",
      "swinging strike: 0.089\n",
      "called strike: 0.211\n",
      "ball: 0.876\n",
      "foul ball: 0.194\n",
      "bunt: 0.000\n",
      "\n",
      "Precision\n",
      "uncategorized: nan\n",
      "in play: 0.327\n",
      "swinging strike: 0.252\n",
      "called strike: 0.361\n",
      "ball: 0.726\n",
      "foul ball: 0.234\n",
      "bunt: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-06c06e2c8c4b>:16: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp/x[:,i].sum()\n"
     ]
    }
   ],
   "source": [
    "quick_analysis_multi(mlp_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_layer_mlp_multi_clf = MLPClassifier(activation='tanh', hidden_layer_sizes=(8,4),\n",
    "                               alpha = 0,\n",
    "                               solver='sgd',\n",
    "                               max_iter=5000,\n",
    "                               learning_rate_init=.03\n",
    "                              )\n",
    "mlp_8_4 = Pipeline([('scaler', StandardScaler()),('mlp',two_layer_mlp_multi_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name = 'mlp_8_4.pickle'\n",
    "try:\n",
    "    #raise Exception\n",
    "    mlp_8_4 = pickle.load(open(clf_name,'rb'))\n",
    "except:\n",
    "    file = open(clf_name,'wb')\n",
    "    mlp_8_4.fit(X_train2,y_train2)\n",
    "    pickle.dump(mlp_8_4,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'uncategorized', 1: 'in play', 2: 'swinging strike', 3: 'called strike', 4: 'ball', 5: 'foul ball', 6: 'bunt'}\n",
      "Train score:\n",
      "0.5285\n",
      "Dev   score:\n",
      "0.5284\n",
      "Dev Confusion matrix:\n",
      "[[   0    0    0    0    2    0    0]\n",
      " [   0  418    2  200  142  155    0]\n",
      " [   0  132    6   55  291  111    0]\n",
      " [   0  256    0  357   87  133    0]\n",
      " [   0   31    3   82 1651   39    0]\n",
      " [   0  295    3  153  171  210    0]\n",
      " [   0    4    0    3    7    1    0]]\n",
      "Recall:\n",
      "uncategorized: 0.000\n",
      "in play: 0.456\n",
      "swinging strike: 0.010\n",
      "called strike: 0.429\n",
      "ball: 0.914\n",
      "foul ball: 0.252\n",
      "bunt: 0.000\n",
      "\n",
      "Precision\n",
      "uncategorized: nan\n",
      "in play: 0.368\n",
      "swinging strike: 0.429\n",
      "called strike: 0.420\n",
      "ball: 0.702\n",
      "foul ball: 0.324\n",
      "bunt: nan\n",
      "[[   0    0    0    0    2    0    0]\n",
      " [   0  418    2  200  142  155    0]\n",
      " [   0  132    6   55  291  111    0]\n",
      " [   0  256    0  357   87  133    0]\n",
      " [   0   31    3   82 1651   39    0]\n",
      " [   0  295    3  153  171  210    0]\n",
      " [   0    4    0    3    7    1    0]]\n",
      "[   2  917  595  833 1806  832   15]\n",
      "[   0 1136   14  850 2351  649    0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-06c06e2c8c4b>:16: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp/x[:,i].sum()\n"
     ]
    }
   ],
   "source": [
    "print(result_dict)\n",
    "\n",
    "quick_analysis_multi(mlp_8_4)\n",
    "\n",
    "print(confusion_matrix(y_dev2,mlp_8_4.predict(X_dev2)))\n",
    "print(confusion_matrix(y_dev2,mlp_8_4.predict(X_dev2)).sum(axis=1))\n",
    "print(confusion_matrix(y_dev2,mlp_8_4.predict(X_dev2)).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_12_7 = MLPClassifier(activation='tanh', hidden_layer_sizes=(12,7),\n",
    "                               alpha = 0,\n",
    "                               solver='sgd',\n",
    "                               max_iter=5000,\n",
    "                               learning_rate_init=.03\n",
    "                              )\n",
    "mlp_12_7 = Pipeline([('scaler', StandardScaler()),('mlp',mlp_12_7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name = 'mlp_12_7.pickle'\n",
    "try:\n",
    "    #raise Exception\n",
    "    mlp_12_7 = pickle.load(open(clf_name,'rb'))\n",
    "except:\n",
    "    file = open(clf_name,'wb')\n",
    "    mlp_12_7.fit(X_train2,y_train2)\n",
    "    pickle.dump(mlp_12_7,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:\n",
      "0.5287\n",
      "Dev   score:\n",
      "0.5288\n",
      "Dev Confusion matrix:\n",
      "[[   0    0    0    0    2    0    0]\n",
      " [   0  418   39  182  132  146    0]\n",
      " [   0  102   52   51  260  130    0]\n",
      " [   0  274   14  336   94  115    0]\n",
      " [   0   22   39   64 1643   38    0]\n",
      " [   0  289   32  144  172  195    0]\n",
      " [   0    4    0    1    9    1    0]]\n",
      "Recall:\n",
      "uncategorized: 0.000\n",
      "in play: 0.456\n",
      "swinging strike: 0.087\n",
      "called strike: 0.403\n",
      "ball: 0.910\n",
      "foul ball: 0.234\n",
      "bunt: 0.000\n",
      "\n",
      "Precision\n",
      "uncategorized: nan\n",
      "in play: 0.377\n",
      "swinging strike: 0.295\n",
      "called strike: 0.432\n",
      "ball: 0.711\n",
      "foul ball: 0.312\n",
      "bunt: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-06c06e2c8c4b>:16: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp/x[:,i].sum()\n"
     ]
    }
   ],
   "source": [
    "quick_analysis_multi(mlp_12_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_15_10_7 = MLPClassifier(activation='tanh', hidden_layer_sizes=(15,10,7),\n",
    "                               alpha = 0,\n",
    "                               solver='sgd',\n",
    "                               max_iter=5000,\n",
    "                               learning_rate_init=.03\n",
    "                              )\n",
    "mlp_15_10_7 = Pipeline([('scaler', StandardScaler()),('mlp',mlp_15_10_7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name = 'mlp_15_10_7.pickle'\n",
    "try:\n",
    "    #raise Exception\n",
    "    mlp_15_10_7 = pickle.load(open(clf_name,'rb'))\n",
    "except:\n",
    "    file = open(clf_name,'wb')\n",
    "    mlp_15_10_7.fit(X_train2,y_train2)\n",
    "    pickle.dump(mlp_15_10_7,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:\n",
      "uncategorized: 0.000\n",
      "in play: 0.475\n",
      "swinging strike: 0.074\n",
      "called strike: 0.465\n",
      "ball: 0.910\n",
      "foul ball: 0.225\n",
      "bunt: 0.000\n",
      "\n",
      "Precision\n",
      "uncategorized: 1.000\n",
      "in play: 0.800\n",
      "swinging strike: 0.980\n",
      "called strike: 0.884\n",
      "ball: 0.816\n",
      "foul ball: 0.915\n",
      "bunt: 1.000\n"
     ]
    }
   ],
   "source": [
    "#quick_analysis_multi(mlp_15_10_7)\n",
    "x = confusion_matrix(y_dev2,mlp_15_10_7.predict(X_dev2))\n",
    "print('Recall:')\n",
    "for i in range(x.shape[1]):\n",
    "    recall = x[i,i]/x[i,:].sum()\n",
    "    print(\"{}: {:.3f}\".format(result_dict[i],recall))\n",
    "    \n",
    "print('\\nPrecision')\n",
    "for i in range(x.shape[1]):\n",
    "    negatives = x.sum()-x[i,:].sum()\n",
    "    true_negatives = (x.sum() - x[i,:].sum())-(x[:,i].sum()-x[i,i].sum())\n",
    "    precision = true_negatives/negatives\n",
    "    print(\"{}: {:.3f}\".format(result_dict[i],precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "\n",
    "That was a satisfying experience.  Getting an MLP to substantially outperform the Logistic Regression was cool, though complex models barely outperformed simple ones. Sure, a score of .53 isn't very high, but the problem we're looking at is also really hard. There are at least two large factors in the outcome of a pitch besides the pitch (I think). One is the count. Major League hitters don't offer at a curveball that's heading toward the bottom corner of the strike zone in a 2-0 count. The other factor is the hitter himself. Some swing more than others, and some make contact more than others. \n",
    "\n",
    "For fun, I want to see how much difference including the count makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "subset = physical_data + ['strikes','balls','result']\n",
    "data3 = df[subset].copy()\n",
    "data3.dropna(inplace = True)\n",
    "X_train3, X_hold3, y_train3, y_hold3 = train_test_split(data3[subset].drop('result', axis=1),\n",
    "                                                    data2['result'], test_size=10000)\n",
    "X_dev3, X_test3, y_dev3, y_test3 = train_test_split(X_hold3, y_hold3, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_6 = MLPClassifier(activation='tanh', hidden_layer_sizes=(6),\n",
    "                               alpha = 0,\n",
    "                               solver='sgd',\n",
    "                               max_iter=5000,\n",
    "                               learning_rate_init=.03\n",
    "                              )\n",
    "\n",
    "mlp_6 = Pipeline([('scaler', StandardScaler()),('mlp', mlp_4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_name = 'mlp_6.pickle'\n",
    "try:\n",
    "    #raise Exception\n",
    "    mlp_6 = pickle.load(open(clf_name,'rb'))\n",
    "except:\n",
    "    file = open(clf_name,'wb')\n",
    "    mlp_6.fit(X_train3,y_train3)\n",
    "    pickle.dump(mlp_6,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 457   38  242  118   94    0]\n",
      " [ 120   36  113  231   52    0]\n",
      " [ 138   12  472  134   37    0]\n",
      " [  25   40   60 1653   23    0]\n",
      " [ 370   37  209  171  103    0]\n",
      " [   0    0    6    8    1    0]]\n"
     ]
    }
   ],
   "source": [
    "mlp_6.score(X_dev3,y_dev3)\n",
    "print(confusion_matrix(y_dev3,mlp_6.predict(X_dev3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('mlp',\n",
       "                 MLPClassifier(activation='tanh', alpha=0,\n",
       "                               hidden_layer_sizes=(12, 7),\n",
       "                               learning_rate_init=0.03, max_iter=5000,\n",
       "                               solver='sgd'))])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_12_7.fit(X_train3,y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 426   17  228  129  149    0]\n",
      " [  96   22  103  223  108    0]\n",
      " [ 124    1  530   98   40    0]\n",
      " [  22   27   71 1657   24    0]\n",
      " [ 305   18  210  162  195    0]\n",
      " [   2    0    4    7    2    0]]\n"
     ]
    }
   ],
   "source": [
    "mlp_12_7.score(X_dev3,y_dev3)\n",
    "print(confusion_matrix(y_dev3,mlp_12_7.predict(X_dev3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playtime...\n",
    "\n",
    "Okay, I think there's not much else to be gained here unless I want to try batter id as categorical data. But while I'm sitting here with a big data set that I've played with a little, I think I want to learn a little about whether training time can be optimized better. The above was very slow. \n",
    "\n",
    "I ran a bunch of the code below (_sometimes in forms that I edited later._) Let's summarize what I learned:\n",
    "1. The size of a hidden layer doesn't necessarily slow down learning. It seems like convergence can be reached faster if it's more complex.\n",
    "1. The difference in performance of the model didn't change much at all based on whether I had 5,000 or 50,000 examples. \n",
    "> - Lesson: When playing around with this stuff and testing lots of models, it would behoove you to investigate where diminishing returns on training set size and model perfomance seems to get real. Save yourself some time getting a few parameters right, then tune with a larger data set for fine details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_sandbox = MLPClassifier(activation='tanh', hidden_layer_sizes=(1),\n",
    "                               alpha = 0,\n",
    "                               solver='sgd',\n",
    "                               max_iter=5000,\n",
    "                               learning_rate_init=.03\n",
    "                              )\n",
    "mlp_sandbox = Pipeline([('scaler', StandardScaler()),('mlp',mlp_sandbox)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_quick, X_slow, y_quick, y_slow = train_test_split(X_train3, y_train3, train_size=5_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.433730602264404\n",
      "0.5386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5428"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "#mlp_sandbox.activation = 'relu'\n",
    "mlp_sandbox.hidden_layer_sizes=(1)\n",
    "#mlp_sandbox.learning_rate_init=.01\n",
    "mlp_sandbox.fit(X_quick,y_quick)\n",
    "end = time.time()\n",
    "print(end - start) ##20.91 seconds on the first pass\n",
    "print(mlp_sandbox.score(X_quick,y_quick))\n",
    "mlp_sandbox.score(X_dev3,y_dev3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9261984825134277\n",
      "0.5448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5442"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "#mlp_sandbox.activation = 'relu'\n",
    "#mlp_sandbox.hidden_layer_sizes=(12,4)\n",
    "#mlp_sandbox.learning_rate_init=.01\n",
    "mlp_sandbox.fit(X_quick,y_quick)\n",
    "end = time.time()\n",
    "print(end - start) ##20.91 seconds on the first pass\n",
    "print(mlp_sandbox.score(X_quick,y_quick))\n",
    "mlp_sandbox.score(X_dev3,y_dev3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0856385231018066\n",
      "0.5664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5446"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mlp_sandbox.activation = 'relu'\n",
    "mlp_sandbox.hidden_layer_sizes=(12,4)\n",
    "#mlp_sandbox.learning_rate_init=.01\n",
    "\n",
    "start = time.time()\n",
    "mlp_sandbox.fit(X_quick,y_quick)\n",
    "end = time.time()\n",
    "print(end - start) ##21.57 seconds on the first pass\n",
    "print(mlp_sandbox.score(X_quick,y_quick))\n",
    "mlp_sandbox.score(X_dev3,y_dev3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.90644931793213\n",
      "0.56468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5596"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_sandbox.activation = 'relu'\n",
    "#mlp_sandbox.hidden_layer_sizes=12\n",
    "mlp_sandbox.learning_rate_init=.01\n",
    "\n",
    "start = time.time()\n",
    "mlp_sandbox.fit(X_quick,y_quick)\n",
    "end = time.time()\n",
    "print(end - start) ##35.91 seconds on the first pass\n",
    "print(mlp_sandbox.score(X_quick,y_quick))\n",
    "mlp_sandbox.score(X_dev3,y_dev3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.59362196922302\n",
      "0.56588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5672"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_sandbox.activation = 'tanh'\n",
    "#mlp_sandbox.hidden_layer_sizes=12\n",
    "mlp_sandbox.learning_rate_init=.03\n",
    "\n",
    "mlp_sandbox.solver='sgd'\n",
    "mlp_sandbox.learning_rate = 'adaptive'\n",
    "start = time.time()\n",
    "mlp_sandbox.fit(X_quick,y_quick)\n",
    "end = time.time()\n",
    "print(end - start) ##38.59 seconds on the first pass\n",
    "print(mlp_sandbox.score(X_quick,y_quick))\n",
    "mlp_sandbox.score(X_dev3,y_dev3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.500808477401733\n",
      "0.56254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5648"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_sandbox.activation = 'tanh'\n",
    "#mlp_sandbox.hidden_layer_sizes=12\n",
    "mlp_sandbox.learning_rate_init=.1\n",
    "\n",
    "mlp_sandbox.solver='sgd'\n",
    "mlp_sandbox.learning_rate = 'adaptive'\n",
    "start = time.time()\n",
    "mlp_sandbox.fit(X_quick,y_quick)\n",
    "end = time.time()\n",
    "print(end - start) ##31.5 seconds on the first pass\n",
    "print(mlp_sandbox.score(X_quick,y_quick))\n",
    "mlp_sandbox.score(X_dev3,y_dev3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
